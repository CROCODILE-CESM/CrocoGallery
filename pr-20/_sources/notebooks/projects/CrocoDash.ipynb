{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CrocoDash Workshop Project 2025\n",
    "\n",
    "\n",
    "In this notebook, the code has the most basic, simplest regional ocean model setup possible through CrocoDash. In the comments and descriptions, we'll provide all the ways you can add and build on this demo (recreate a specific domain - like GFDL's NWA12, run with CICE - the sea-ice model in CESM, run with MARBL - the ocean BGC model in CESM, and beyond!) \n",
    "\n",
    "\n",
    "A typical workflow of utilizing CrocoDash consists of four main steps:\n",
    "\n",
    "1. Generate a regional MOM6 domain.\n",
    "2. Create the CESM case.\n",
    "3. Prepare ocean forcing data.\n",
    "4. Build and run the case.\n",
    "\n",
    "Every single specialization of CrocoDash will use this framework.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECTION 1: Generate a regional MOM6 domain\n",
    "\n",
    "We begin by defining a regional MOM6 domain using CrocoDash. To do so, we first generate a horizontal grid. We then generate the topography by remapping an existing bathymetric dataset to our horizontal grid. Finally, we define a vertical grid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1.1: Horizontal Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CrocoDash.grid import Grid\n",
    "\n",
    "grid = Grid(\n",
    "  resolution = 0.01, # in degrees\n",
    "  xstart = 278.0, # min longitude in [0, 360]\n",
    "  lenx = 3.0, # longitude extent in degrees\n",
    "  ystart = 7.0, # min latitude in [-90, 90]\n",
    "  leny = 3.0, # latitude extent in degrees\n",
    "  name = \"panama1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above cell is a way to generate a rectangular lat/lon grid through CrocoDash\n",
    "\n",
    "If you're interested in using an already generated regional grid, you can do that by passing in a supergrid, like in this demo: https://crocodile-cesm.github.io/CrocoGallery/notebooks/features/add_grids.html.\n",
    "\n",
    "If you're interested in subsetting an already generated global grid, you can do that by passing in lat/lon args, like in this demo: https://crocodile-cesm.github.io/CrocoGallery/notebooks/features/subset_global.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1.2: Topography\n",
    "\n",
    "The below three cells are a way to generate topography with a given grid using the [GEBCO](https://www.gebco.net/) dataset. \n",
    "\n",
    "If you're interested in using a previously generated topography for your grid, you can do that by passing in a topography file, like in this demo: https://crocodile-cesm.github.io/CrocoGallery/notebooks/features/add_grids.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CrocoDash.topo import Topo\n",
    "\n",
    "topo = Topo(\n",
    "    grid = grid,\n",
    "    min_depth = 9.5, # in meters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bathymetry_path='s3://crocodile-cesm/CrocoDash/data/gebco/GEBCO_2024.zarr/'\n",
    "\n",
    "topo.interpolate_from_file(\n",
    "    file_path = bathymetry_path,\n",
    "    longitude_coordinate_name=\"lon\",\n",
    "    latitude_coordinate_name=\"lat\",\n",
    "    vertical_coordinate_name=\"elevation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate that the topography looks right!\n",
    "topo.depth.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Editing the topography\n",
    "\n",
    "Regridding topography from GEBCO may result in features we do not necessarily want. The Topo Editor is a tool to edit the bathymetry as wanted. You can do things like erasing basins, opening or closing bays, or adjusting the minimum depth. On JupyterHub, remember we need the ipympl extension, which can be installed like this: https://docs.google.com/presentation/d/1ZwM2YKmMumM0kggT9QpgXnizHzCdIaUdO8PBH9TR2ls/edit?slide=id.g38d23f5381c_0_0#slide=id.g38d23f5381c_0_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "from CrocoDash.topo_editor import TopoEditor\n",
    "TopoEditor(topo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1.3: Vertical Grid\n",
    "\n",
    "The below cell generates a vertical grid using a hyperbolic function. We can also create a uniform grid instance, or use a previously generated vertical grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CrocoDash.vgrid import VGrid\n",
    "\n",
    "vgrid  = VGrid.hyperbolic(\n",
    "    nk = 75, # number of vertical levels\n",
    "    depth = topo.max_depth,\n",
    "    ratio=20.0 # target ratio of top to bottom layer thicknesses\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.close()\n",
    "# Create the plot\n",
    "for depth in vgrid.z:\n",
    "    plt.axhline(y=depth, linestyle='-')  # Horizontal lines\n",
    "\n",
    "plt.ylim(max(vgrid.z) + 10, min(vgrid.z) - 10)  # Invert y-axis so deeper values go down\n",
    "plt.ylabel(\"Depth\")\n",
    "plt.title(\"Vertical Grid\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECTION 2: Create the CESM case\n",
    "\n",
    "After generating the MOM6 domain, the next step is to create a CESM case using CrocoDash. This process is straightforward and involves instantiating the CrocoDash Case object. The Case object requires the following inputs:\n",
    "\n",
    " - CESM Source Directory: A local path to a compatible CESM source copy.\n",
    " - Case Name: A unique name for the CESM case.\n",
    " - Input Directory: The directory where all necessary input files will be written.\n",
    " - MOM6 Domain Objects: The horizontal grid, topography, and vertical grid created in the previous section.\n",
    " - Project ID: (Optional) A project ID, if required by the machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.1: Specify case name and directories:\n",
    "\n",
    "Begin by specifying the case name and the necessary directory paths. Ensure the CESM root directory points to your own local copy of CESM. Below is an example setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CESM case (experiment) name\n",
    "casename = \"panama-not\"\n",
    "\n",
    "# CESM source root (Update this path accordingly!!!)\n",
    "cesmroot =\"/home/runner/work/CrocoGallery/CrocoGallery/CESM/\"\n",
    "\n",
    "# Place where all your input files go \n",
    "inputdir = Path.home() / \"croc_input\" / casename\n",
    "    \n",
    "# CESM case directory\n",
    "caseroot = Path.home() / \"croc_cases\" / casename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.2: Create the Case\n",
    "\n",
    "To create the CESM case, instantiate the `Case` object as shown below. This will automatically set up the CESM case based on the provided inputs: The `cesmroot` argument specifies the path to your local CESM source directory.\n",
    "The `caseroot` argument defines the directory where the case will be created. CrocoDash will handle all necessary namelist modifications and XML changes to align with the MOM6 domain objects generated earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CrocoDash.case import Case\n",
    "\n",
    "case = Case(\n",
    "    cesmroot = cesmroot,\n",
    "    caseroot = caseroot,\n",
    "    inputdir = inputdir,\n",
    "    ocn_grid = grid,\n",
    "    ocn_vgrid = vgrid,\n",
    "    ocn_topo = topo,\n",
    "    project = 'CESM0030',\n",
    "    override = True,\n",
    "    machine = \"derecho\",\n",
    "    compset = \"1850_DATM%JRA_SLND_SICE_MOM6_SROF_SGLC_SWAV\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: Prepare ocean forcing data\n",
    "\n",
    "We need to cut out our ocean forcing. The package expects an initial condition and one time-dependent segment per non-land boundary. Naming convention is `\"east_unprocessed\"` for segments and `\"ic_unprocessed\"` for the initial condition.\n",
    "\n",
    "In this notebook, we are forcing with the Copernicus Marine \"Glorys\" reanalysis dataset. There's a function in the `CrocoDash` package, called `configure_forcings`, that generates a bash script to download the correct boundary forcing files for your experiment. First, you will need to create an account with Copernicus, and then call `copernicusmarine login` to set up your login details on your machine. Then you can run the `get_glorys_data.sh` bash script.\n",
    "\n",
    "## Step 3.1 Configure Initial Conditions and Forcings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case.configure_forcings(\n",
    "    date_range = [\"2020-01-01 00:00:00\", \"2020-01-09 00:00:00\"],\n",
    "    function_name=\"get_glorys_data_from_rda\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Step 3.3: Process forcing data\n",
    "\n",
    "In this final step, we call the `process_forcings` method of CrocoDash to cut out and interpolate the initial condition as well as all boundaries. CrocoDash also updates MOM6 runtime parameters and CESM xml variables accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case.process_forcings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4: Build and run the case\n",
    "\n",
    "After completing the previous steps, you are ready to build and run your CESM case. Begin by navigating to the case root directory specified during the case creation. Before proceeding, review the `user_nl_mom` file located in the case directory. This file contains MOM6 parameter settings that were automatically generated by CrocoDash. Carefully examine these parameters and make any necessary adjustments to fine-tune the model for your specific requirements. While CrocoDash aims to provide a solid starting point, further tuning and adjustments are typically necessary to improve the model for your use case.\n",
    "\n",
    "Once you have reviewed and modified the parameters as needed, you can build and execute the case using the following commands: \n",
    "```\n",
    "./case.build\n",
    "./case.submit\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CrocoDash",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
